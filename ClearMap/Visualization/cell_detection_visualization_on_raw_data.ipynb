{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell detection visualization (with raw data)\n",
    "\n",
    "### Simple tutorial to overlay raw lightsheet images with cells detected using ClearMap.\n",
    "\n",
    "Depends on [ClearMapCluster](https://github.com/PrincetonUniversity/ClearMapCluster) installation and processed lightsheet images acquired using the LaVision UltraMicroscope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np, os, time, cv2, pandas as pd\n",
    "from skimage.external import tifffile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define key functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_merged_stack(pth, dst, dtype = \"uint16\", resizef = 3):\n",
    "    \"\"\"\n",
    "    resize function for large image stacks using cv2\n",
    "    inputs:\n",
    "        pth = 4d stack, memmap array or numpy array\n",
    "        dst = path of tif file to save\n",
    "        dtype = default uint16\n",
    "        resizef = default 6\n",
    "    \"\"\"\n",
    "\n",
    "    #read file\n",
    "    if pth[-4:] == \".tif\": img = tifffile.imread(pth)\n",
    "    elif pth[-4:] == \".npy\": img = np.lib.format.open_memmap(pth, dtype = dtype, mode = \"r\")\n",
    "    else: img = pth #if array was input\n",
    "\n",
    "    z,y,x,ch = img.shape\n",
    "    resz_img = np.zeros((z, int(y/resizef), int(x/resizef), ch))\n",
    "\n",
    "    for i in range(z):\n",
    "        for j in range(ch):\n",
    "            #make the factors - have to resize both image and cell center array\n",
    "            xr = int(img[i, :, :, j].shape[1] / resizef); yr =  int(img[i, :, :, j].shape[0] / resizef)\n",
    "            im = cv2.resize(img[i, :, :, j], (xr, yr), interpolation=cv2.INTER_LINEAR)\n",
    "            resz_img[i, :, :, j] = im.astype(dtype)\n",
    "\n",
    "    tifffile.imsave(dst, resz_img.astype(dtype))\n",
    "\n",
    "    return dst\n",
    "\n",
    "def check_cell_center_to_fullsizedata(brain, zstart, zstop, dst, resizef, annotation=False):\n",
    "    \"\"\"\n",
    "    maps cnn cell center coordinates to full size cell channel images\n",
    "    inputs:\n",
    "        brain = path to lightsheet processed directory\n",
    "        zstart = beginning of zslice\n",
    "        zstop = end of zslice\n",
    "        dst = path of tif stack to save\n",
    "    NOTE: 20+ PLANES CAN OVERLOAD MEMORY\n",
    "    \"\"\"\n",
    "    print(os.path.basename(brain))\n",
    "    start = time.time()\n",
    "\n",
    "    #doing things without loading parameter dict\n",
    "    fzfld = os.path.join(brain, \"full_sizedatafld\")\n",
    "\n",
    "    #exception if only 1 channel is imaged\n",
    "    cellch = os.path.join(fzfld, [xx for xx in os.listdir(fzfld) if \"647\" in xx][0])\n",
    "\n",
    "    #not the greatest way to do things, but works\n",
    "    src = [os.path.join(cellch, xx) for xx in os.listdir(cellch) if xx[-3:] == \"tif\" and int(xx[-7:-4]) in range(zstart, zstop)]; src.sort()\n",
    "\n",
    "    raw = np.zeros((len(src), tifffile.imread(src[0]).shape[0], tifffile.imread(src[0]).shape[1]))\n",
    "\n",
    "    for i in range(len(src)):\n",
    "        raw[i, :, :] = tifffile.imread(src[i])\n",
    "\n",
    "    pth = os.path.join(brain, \"clearmap_cluster_output/cells.npy\")\n",
    "    cells = np.load(pth) #this is in x,y,z!!!!!!!!!!!!!!!\n",
    "\n",
    "    cells = cells[(cells[:, 2] >= zstart) & (cells[:, 2] <= zstop-1)] #-1 to account for range\n",
    "\n",
    "    cell_centers = np.zeros(raw.shape)\n",
    "    print(\"\\n******making the corresponding cell map******\\n\")\n",
    "    for i, r in enumerate(cells):\n",
    "        cell_centers[r[2]-zstart, r[1]-1:r[1]+1, r[0]-1:r[0]+1] = 50000\n",
    "\n",
    "    rbg = np.stack([raw.astype(\"uint16\"), cell_centers.astype(\"uint16\"), np.zeros_like(raw)], -1)\n",
    "    #add the annotation volume transformed-to-raw-space as the 'blue' channel in the RGB stack (3 color overlay)\n",
    "    if annotation:\n",
    "        print(\"\\n******making the annotation map******\\n\")\n",
    "        annotation = os.path.join(annotation, \"transformed_annotations/single_tifs\") #the directory structure of these annotation volumes\n",
    "        src = [os.path.join(annotation, xx) for xx in os.listdir(annotation) if xx[-3:] == \"tif\" and int(xx[-7:-4]) in range(zstart, zstop)]; src.sort()\n",
    "        #populate corresponding annotation volume\n",
    "        ann_raw = np.zeros((len(src), tifffile.imread(src[0]).shape[0], tifffile.imread(src[0]).shape[1]))\n",
    "        for i in range(len(src)):\n",
    "            ann_raw[i, :, :] = tifffile.imread(src[i])\n",
    "        #add 'blue' channel to rbg stack\n",
    "        rbg = np.stack([raw.astype(\"uint16\"), cell_centers.astype(\"uint16\"), ann_raw.astype(\"uint16\")], -1)\n",
    "        #FIXME: i am converting the annotation images to a 16 bit file. if the original annotation volume was 32 bit,\n",
    "        #this can cause problems with the out of range structures. either use only 16 bit annotation volumes\n",
    "        #for this or try something else\n",
    "        \n",
    "    print(\"\\n******resizing (if requested)******\\n\")\n",
    "    resize_merged_stack(rbg, os.path.join(dst, \"{}_raw_cell_centers_resizedfactor{}_z{}-{}.tif\".format(os.path.basename(brain),\n",
    "                                          resizef, zstart, zstop)), \"uint16\", resizef)\n",
    "\n",
    "    print(\"took %0.1f seconds to make merged maps for %s\" % ((time.time()-start), brain))\n",
    "\n",
    "def check_cell_center_to_resampled(brain, zstart, zstop, dst):\n",
    "    \"\"\"\n",
    "    maps cnn cell center coordinates to resampled stack\n",
    "    inputs:\n",
    "        brain = path to lightsheet processed directory\n",
    "        zstart = beginning of zslice\n",
    "        zstop = end of zslice\n",
    "        dst = path of tif stack to save\n",
    "    NOTE: 20+ PLANES CAN OVERLOAD MEMORY\n",
    "    \"\"\"\n",
    "    print(os.path.basename(brain))\n",
    "    start = time.time()\n",
    "\n",
    "    #doing things without loading parameter dict, could become a problem\n",
    "    tifs = [xx for xx in os.listdir(brain) if xx[-4:] == \".tif\"]; tifs.sort()\n",
    "    raw = tifffile.imread(tifs[len(tifs)-1])\n",
    "\n",
    "    pth = os.path.join(brain, \"clearmap_cluster_output/cells.npy\")\n",
    "    cells = np.load(pth) #this is in x,y,z!!!!!!!!!!!!!!!\n",
    "\n",
    "    cells = cells[(cells[:, 2] >= zstart) & (cells[:, 2] <= zstop-1)] #-1 to account for range\n",
    "\n",
    "    cell_centers = np.zeros(raw.shape)\n",
    "    print(\"\\n******making the corresponding cell map******\\n\")\n",
    "    for i, r in enumerate(cells):\n",
    "        cell_centers[r[2]-zstart, r[1]-1:r[1]+1, r[0]-1:r[0]+1] = 50000\n",
    "\n",
    "    rbg = np.stack([raw.astype(\"uint16\"), cell_centers.astype(\"uint16\"), np.zeros_like(raw)], -1)\n",
    "    print(\"\\n******resizing******\\n\")\n",
    "    resize_merged_stack(rbg, os.path.join(dst, \"{}_raw_cell_centers_resized_z{}-{}.tif\".format(os.path.basename(brain),\n",
    "                                          zstart, zstop)), \"uint16\", 6)\n",
    "\n",
    "    print(\"took %0.1f seconds to make merged maps for %s\" % ((time.time()-start), brain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths to source directory (where the ClearMapCluster processed directory exists) and destination directory (where you want to save it):\n",
    "\n",
    "### Overlay annotations (optional)\n",
    "\n",
    "If you have transformed your annotation volume corresponding the atlas to \"raw\" space (aka your full-resolution images), you can optionally specify the location of the transformed annotations by animal name (`annotation`). These transformations are typically done using `transformix` in the `elastix` package and should be done prior to running this notebook (see Z.D.'s [helper scripts](https://github.com/PrincetonUniversity/lightsheet_helper_scripts/blob/master/registration/annotation_volume_analysis/transform_annotations_to_fullsize_cfos.py) for an example on how to do this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"/jukebox/LightSheetData/falkner-mouse/scooter/clearmap_processed\"\n",
    "dst = \"/jukebox/LightSheetData/falkner-mouse/scooter/qc\"\n",
    "annotation = \"/jukebox/LightSheetData/falkner-mouse/scooter/qc/annotation_volumes_in_raw_space\"\n",
    "#make destination directory if it does not already exist\n",
    "if not os.path.exists(dst): os.mkdir(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for visualization\n",
    "\n",
    "Raw lightsheet images are typically 2000 x 2000 pixels in size with ~700-1500 z-planes. Thus, the whole brain volume with an overlay of cells detected cannot be visualized with this method at once. You can, however, select a range of z-planes at a time so the script can execute and output a reasonably-sized volume to visualize on a standard desktop or laptop. \n",
    "\n",
    "As a reference, `z=0,1,2,...` represents the plane of the brain volume based on the orientation of imaging. If you image from dorsal --> ventral horizontally, `z=0` represents the dorsal-most area of the brain, and so on. \n",
    "\n",
    "You can set a `zstart` and `zstop` value which represents the number of planes you want to visualize at a time. To convert the # of planes into microns, you can simply multiple the number of planes you are visualizing by the z-step you selected during imaging. In this case, 20 planes = 20 * 10 micron z-step = 200 microns\n",
    "\n",
    "#### Warning: typically you would not want to do more than 20 planes to run this on a standard desktop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zstart = 400; zstop = 420 #z-plane #'s you want to visualize at a time, 250-400 is probably ideal for thalamus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set a `resizef` as a factor by which you want to downsize your raw data and cell centers accordingly to visualize the overlay. You can do this if your machine has memory constraints, but typically visualizing the cell centers on the raw image is ideal as this is the resolution in which the cells were detected originally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizef = 1 #factor by which to downsize raw and cell center overlay, keep 1 if you do not want to downsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the overlay function\n",
    "\n",
    "You can pick the names of brains/animals in your processed directory for which you want to make the cell center overlay, and execute the main `check_cell_center_to_fullsizedata()` iteratively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmnp4\n",
      "\n",
      "******making the corresponding cell map******\n",
      "\n",
      "\n",
      "******making the annotation map******\n",
      "\n",
      "\n",
      "******resizing (if requested)******\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanglab/anaconda3/envs/lightsheet/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if sys.path[0] == '':\n",
      "/home/wanglab/anaconda3/envs/lightsheet/lib/python3.7/site-packages/ipykernel_launcher.py:13: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 93.5 seconds to make merged maps for /jukebox/LightSheetData/falkner-mouse/scooter/clearmap_processed/fmnp4\n"
     ]
    }
   ],
   "source": [
    "ids = [\"fmnp4\"]\n",
    "\n",
    "for i in ids:\n",
    "    brain = os.path.join(src, i)\n",
    "    annotation = os.path.join(annotation, i)\n",
    "    check_cell_center_to_fullsizedata(brain, zstart, zstop, dst, resizef, annotation=annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create overlays using the downsized whole-brain volume already created in the ClearMapCluster pipeline for registration, which saves an extra step of downsizing and may be friendlier for a laptop run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [\"fmnp4\"]\n",
    "\n",
    "for i in ids:\n",
    "    brain = os.path.join(src, i)\n",
    "    check_cell_center_to_resampled(brain, zstart, zstop, dst, resizef)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
